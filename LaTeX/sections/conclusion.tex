\section{Conclusion}
Observing the results given we can conclude that with the use of the Myoware sensors and Analog Discovery studio, the signal 
acquisition was processed without any large issues. This was due to the signals received from the sensors being consistent 
from user to user. When examining the signal no notable features were found leading to raw data being used.
The Analog Discovery studio studio made processing and transferring the signals to Python lightwork.


After inspecting both Python implementations and the data used to train and test them, it was concluded that the problem behind the accuracy
of the models might be the data itself. The data files were shuffled before being fed into the model to avoid learning on the test subject
itself, however, the data was not preprocessed in any other way aside from windowing. The data from each file was fed into the model in the 
same order as it was collected, which followed a consistent class order. This consistent class order might have led the model's gradient to 
get stuck in a local minimum, which would explain the 25\% accuracy on the validation set.

Another aspect to take into account in regards to the training of the \acrshort{rnn} is how the data is fed to the model. The issues
with the training could be caused by the repetitive nature of the data, where the same movement order is repeated. Splitting the data
into atomic movements and then combining them in a random order could be a solution to this issue.
\\
The weights of the \acrshort{rnn} could not be transferred to LabView without great difficulties due to the lack of clarity provided by
PyTorch. Making use of methods that would allow for either easier weight extraction or for the model to be trained
directly in LabView would be preferred.
\\
Due to time constraints, the method for driving the actuator at variable speeds was not implemented. The steps to implement it
would involve either a separate function analyzing the amplitude of the inputs, or comparing the outputs of the RNN,
with higher certainty leading to higher speed.
\\
During testing of the exoskeleton made by the last group, the exoskeleton finished a full movement from start to stop approximately 
one second after the user finished the movement based on observation of a video from the previous group. During testing of the RNN 
code in Labview a full iteration took 230 ms, showing a clear improvement.


\subsection{Future Work}

Any future projects should consider acquiring and setting up a motor controller to enable feedback on any other aspect of the future work
as well as solving the issues with the \acrshort{rnn} training in Python as their main priorities.

Once the arm moves, two main directions of improvement could be considered. The first is to mount it on a person. After implementing and mounting it the second direction would be to
add more DoF for example shoulder movement.